#!/usr/bin/env bash

# Copyright 2017-2020 EPAM Systems, Inc. (https://www.epam.com/)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

SGE_WORKER_SETUP_TASK="SGEWorkerSetup"
CURRENT_PID=$$

reset_local_host_config() {
    qconf -sconf $HOSTNAME &> /dev/null
    if [ "$?" -eq "0" ]; then
        qconf -dconf $HOSTNAME
    fi
}

add_worker() {
    local _QUEUE=$1
    local _HOSTLIST=$2
    local _SLOTS=$3
    local _MASTER_NAME=$4

    if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
        ssh $CP_SSH_EXTRA_ARGS -t "$_MASTER_NAME" bash -c "'
        # add to the execution host list
        TMPFILE=/tmp/sge.hostname-$HOSTNAME
        echo -e \"hostname $HOSTNAME\nload_scaling NONE\ncomplex_values NONE\nuser_lists NONE\nxuser_lists NONE\nprojects NONE\nxprojects NONE\nusage_scaling NONE\nreport_variables NONE\" > \$TMPFILE
        qconf -Ae \$TMPFILE
        rm \$TMPFILE

        if [ "$_SLOTS" ]; then
            qconf -aattr queue slots \"[$HOSTNAME=$_SLOTS]\" $_QUEUE
        fi

        # add to the all hosts list
        qconf -aattr hostgroup hostlist $HOSTNAME $_HOSTLIST
        if [ \"$cluster_role_type\" = \"additional\" ]
        then
            # additional hosts should be disabled until GE autoscaler enables them
            qmod -d $_QUEUE@$HOSTNAME
        else
            # enable the host for the _QUEUE, in case it was disabled and not removed
            qmod -e $_QUEUE@$HOSTNAME
        fi

        qconf -as $HOSTNAME
        qconf -ah $HOSTNAME
        '"
    elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then
        cd "$SGE_ROOT"
        ssh $CP_SSH_EXTRA_ARGS -o "StrictHostKeyChecking=no" "$_MASTER_NAME" bash --login -c "'qconf -ah $HOSTNAME'"
        copy_qmaster_configuration $_MASTER_NAME
        run_redhat_installation "worker"

        if [ "$_SLOTS" ]; then
            qconf -aattr queue slots "[$HOSTNAME=$_SLOTS]" $_QUEUE
        fi

        qconf -aattr hostgroup hostlist $HOSTNAME $_HOSTLIST
        if [ "$cluster_role_type" = "additional" ]
        then
            # additional hosts should be disabled until GE autoscaler enables them
            qmod -d $_QUEUE@$HOSTNAME
        else
            # enable the host for the _QUEUE, in case it was disabled and not removed
            qmod -e $_QUEUE@$HOSTNAME
        fi
        qconf -as $HOSTNAME
        qconf -ah $HOSTNAME
    fi

    reset_local_host_config
}

remove_worker() {
    local _QUEUE=$1
    local _HOSTLIST=$2

    qconf -purge queue slots "$_QUEUE@$HOSTNAME"
    qconf -dattr hostgroup hostlist "$HOSTNAME" "$_HOSTLIST"
}

run_redhat_installation() {
    _SGE_ROLE=$1

    cat > ./grid.conf <<EOL
    SGE_ROOT="/opt/sge"
    SGE_QMASTER_PORT=6444
    SGE_EXECD_PORT=6445
    SGE_ENABLE_SMF="false"
    SGE_CLUSTER_NAME="${SGE_CLUSTER_NAME}"
    SGE_JMX_SSL="false"
    SGE_JMX_SSL_CLIENT="false"
    CELL_NAME=default
    ADMIN_USER=$
    QMASTER_SPOOL_DIR="$SGE_ROOT/default/spool/qmaster"
    EXECD_SPOOL_DIR="$SGE_ROOT/default/spool"
    GID_RANGE="20000-30000"
    SPOOLING_METHOD="classic"
    DB_SPOOLING_DIR="spooldb"
    PAR_EXECD_INST_COUNT="20"
    EXECD_SPOOL_DIR_LOCAL="$SGE_ROOT/default/spool/$HOSTNAME"
    SHELL_NAME="ssh"
    DEFAULT_DOMAIN="none"
    ADD_TO_RC="true"
    SET_FILE_PERMS="true"
    RESCHEDULE_JOBS="wait"
    SCHEDD_CONF="1"
    SHADOW_HOST=""
    ADMIN_MAIL="none"
    HOSTNAME_RESOLVING="false"
    EXEC_HOST_LIST="$HOSTNAME"
    SUBMIT_HOST_LIST="$HOSTNAME"
EOL


    ./inst_sge -x -auto ./grid.conf
    result=$?
    ln -s /opt/sge/bin/lx-amd64/* /bin
    check_last_exit_code "$result" "$_SGE_ROLE host was successfully configured" \
                                "Failed to configure $_SGE_ROLE host"

    rm -f ./grid.conf
}

copy_qmaster_configuration() {
    _QMASTER_HOST=$1
    mkdir -p "$SGE_ROOT/$SGE_CELL" \
    && scp -r "$_QMASTER_HOST:$SGE_ROOT/$SGE_CELL/common" "$SGE_ROOT/$SGE_CELL" \
    && chmod -R 777 "$SGE_ROOT/$SGE_CELL"
}

get_linux_dist() {
    result=
    command -v apt-get > /dev/null
    if [ $? -eq 0 ]; then
        result="debian"
    fi

    command -v yum > /dev/null
    if [ $? -eq 0 ]; then
        result="redhat"
    fi

    echo "$result"
}

check_last_exit_code() {
   exit_code=$1
   msg_if_success=$2
   msg_if_fail=$3
   if [[ "$exit_code" -ne 0 ]]; then
        pipe_log_fail "$msg_if_fail" "${SGE_WORKER_SETUP_TASK}"
        kill -s "$CURRENT_PID"
        exit 1
    else
        pipe_log_info "$msg_if_success" "${SGE_WORKER_SETUP_TASK}"
    fi
}

LINUX_DISTRIBUTION=$( get_linux_dist )

pipe_log_info "Installing SGE worker" "$SGE_WORKER_SETUP_TASK"

export SGE_CELL="default"
export SGE_CLUSTER_NAME="CLOUD_PIPELINE"
export CP_CAP_SGE_QUEUE_NAME="${CP_CAP_SGE_QUEUE_NAME:-main.q}"
export CP_CAP_SGE_HOSTLIST_NAME="${CP_CAP_SGE_HOSTLIST_NAME:-@allhosts}"

IFS='@' read -r -a owner_info <<< "$OWNER"
OWNER_NAME="${owner_info[0]}"

MASTER_INFO_RESULT=$(eval "${CP_PYTHON2_PATH} ${COMMON_REPO_DIR}/scripts/cluster_wait_for_master.py --master-id ${parent_id} --task-name SGEMasterSetup")
_MASTER_AWAIT_RESULT=$?
MASTER_INFO=($MASTER_INFO_RESULT)
MASTER_IP=${MASTER_INFO[-1]}
MASTER_NAME=${MASTER_INFO[-2]}
check_last_exit_code $_MASTER_AWAIT_RESULT "Master info received: $MASTER_NAME : $MASTER_IP" "Fail to install SGE worker. Unable to get master information"

# Read the master's environment
CP_CAP_SGE_MASTER_ENV_FILE="${CP_CAP_SCRIPTS_DIR}/sge_master_env.sh"
if [ -f "$CP_CAP_SGE_MASTER_ENV_FILE" ]; then
    source "$CP_CAP_SGE_MASTER_ENV_FILE"
fi

if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
    export SGE_ROOT="/var/lib/gridengine"
    rm -rf /var/lib/gridengine/
    apt-get remove gridengine-client gridengine-common gridengine-master gridengine-exec --purge -y

    echo "gridengine-common       shared/gridenginemaster string  $MASTER_NAME" |  debconf-set-selections
    echo "gridengine-common       shared/gridenginecell   string  default" |  debconf-set-selections
    echo "gridengine-common       shared/gridengineconfig boolean false" |  debconf-set-selections
    echo "gridengine-client       shared/gridenginemaster string  $MASTER_NAME" |  debconf-set-selections
    echo "gridengine-client       shared/gridenginecell   string  default" |  debconf-set-selections
    echo "gridengine-client       shared/gridengineconfig boolean false" |  debconf-set-selections
    echo "postfix postfix/main_mailer_type        select  No configuration" |  debconf-set-selections

    CP_CAP_SGE_VERSION="${CP_CAP_SGE_VERSION:-8.1.9+dfsg-4*}"

    # First install SGE, and fail if error occurs
    DEBIAN_FRONTEND=noninteractive apt-get install -y --allow-unauthenticated -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" gridengine-exec="$CP_CAP_SGE_VERSION" \
        gridengine-client="$CP_CAP_SGE_VERSION" \
        gridengine-common="$CP_CAP_SGE_VERSION" > /dev/null

    check_last_exit_code $? "All SGE packages were installed" "Fail to install SGE worker"

    # Next - try to install any non-mandatory packages, and igore them if error occurs
    DEBIAN_FRONTEND=noninteractive apt-get install -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" sudo locales > /dev/null

    if [ $? -ne 0 ]; then
        pipe_log_warn "Additional SGE packages were not installed, error is ignored" "$SGE_MASTER_SETUP_TASK"
    fi

    ## Configure default locale, see https://github.com/rocker-org/rocker/issues/19
    echo "en_US.UTF-8 UTF-8" >> /etc/locale.gen \
        && locale-gen en_US.UTF-8 \
        && /usr/sbin/update-locale LANG=en_US.UTF-8

    export LC_ALL=en_US.UTF-8
    export LANG=en_US.UTF-8

    echo "$MASTER_NAME" |  tee "$SGE_ROOT"/"$SGE_CELL"/common/act_qmaster

elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then
    export SGE_ROOT="/opt/sge"
    if [ "$CP_CAP_SGE_PREINSTALLED" != "true" ]; then
        yum remove -y -q gridengine-*
        rm -rf /opt/sge/*
        rm -rf /etc/rc.d/init.d/*.CLOUD_PIPELINE

        yum install -y -q perl perl-Env.noarch perl-Exporter.noarch perl-File-BaseDir.noarch \
                            perl-Getopt-Long.noarch perl-libs perl-POSIX-strptime.x86_64 \
                            perl-XML-Simple.noarch jemalloc munge-libs hwloc lesstif csh \
                            ruby xorg-x11-fonts xterm java xorg-x11-fonts-ISO8859-1-100dpi \
                            xorg-x11-fonts-ISO8859-1-75dpi mailx libdb4 libdb4-utils \
                            compat-db-headers compat-db47 libpipeline man-db

        yum install -y -q gridengine \
                            gridengine-debuginfo \
                            gridengine-devel \
                            gridengine-drmaa4ruby \
                            gridengine-execd \
                            gridengine-guiinst \
                            gridengine-qmaster \
                            gridengine-qmon
    fi

    check_last_exit_code $? "All SGE packages were installed" "Fail to install SGE worker"
fi

# By default, all the node cores are going to be used by the SGE worker
# If a certain number of cores, shall be reserved (outside the SGE): CP_CAP_SGE_WORKER_FREE_CORES can be used
# Total number of the worker slots is calculated as (nproc - CP_CAP_SGE_WORKER_FREE_CORES). If the result <= 0: nproc is used 
_WORKER_CORES=$(nproc)
CP_CAP_SGE_WORKER_FREE_CORES="${CP_CAP_SGE_WORKER_FREE_CORES:-0}"
_WORKER_CORES=$(($_WORKER_CORES - $CP_CAP_SGE_WORKER_FREE_CORES))
(( $_WORKER_CORES <= 0 )) && _WORKER_CORES=$(nproc)

if ! check_cp_cap CP_CAP_SGE_DISABLE_DEFAULT_QUEUE \
  || [[ "$cluster_role_type" == "additional" ]]; then
    add_worker "$CP_CAP_SGE_QUEUE_NAME" "$CP_CAP_SGE_HOSTLIST_NAME" "$_WORKER_CORES" $MASTER_NAME
    check_last_exit_code $? "Host was added to $CP_CAP_SGE_QUEUE_NAME queue and $CP_CAP_SGE_HOSTLIST_NAME hostlist" \
                            "Fail to add host to $CP_CAP_SGE_QUEUE_NAME queue and $CP_CAP_SGE_HOSTLIST_NAME hostlist"
fi

export _CP_CAP_SGE_DEFAULT_QUEUE_NAME="$CP_CAP_SGE_QUEUE_NAME"
export _CP_CAP_SGE_DEFAULT_HOSTLIST_NAME="$CP_CAP_SGE_HOSTLIST_NAME"

for sge_profile_script in "$CP_CAP_SCRIPTS_DIR"/sge_profile_*_queue.sh; do
    (
        # shellcheck source=/dev/null
        [[ -e "$sge_profile_script" ]] && source "$sge_profile_script"
        if check_cp_cap "CP_CAP_SGE_QUEUE_STATIC" \
          && [[ "$cluster_role_type" != "additional" ]] \
          && [[ "$CP_CAP_SGE_QUEUE_NAME" != "$_CP_CAP_SGE_DEFAULT_QUEUE_NAME" ]] \
          && [[ "$CP_CAP_SGE_HOSTLIST_NAME" != "$_CP_CAP_SGE_DEFAULT_HOSTLIST_NAME" ]]; then
            add_worker "$CP_CAP_SGE_QUEUE_NAME" "$CP_CAP_SGE_HOSTLIST_NAME" "$_WORKER_CORES" $MASTER_NAME
            check_last_exit_code $? "Host was added to $CP_CAP_SGE_QUEUE_NAME queue and $CP_CAP_SGE_HOSTLIST_NAME hostlist" \
                                    "Fail to add host to $CP_CAP_SGE_QUEUE_NAME queue and $CP_CAP_SGE_HOSTLIST_NAME hostlist"
        fi
        if [[ "$cluster_role_type" == "additional" ]] \
          && [[ "$CP_CAP_SGE_QUEUE_NAME" != "$_CP_CAP_SGE_DEFAULT_QUEUE_NAME" ]] \
          && [[ "$CP_CAP_SGE_HOSTLIST_NAME" != "$_CP_CAP_SGE_DEFAULT_HOSTLIST_NAME" ]]; then
            remove_worker "$CP_CAP_SGE_QUEUE_NAME" "$CP_CAP_SGE_HOSTLIST_NAME"
            check_last_exit_code $? "Host was removed from $CP_CAP_SGE_QUEUE_NAME queue and $CP_CAP_SGE_HOSTLIST_NAME hostlist" \
                                    "Fail to remove host from $CP_CAP_SGE_QUEUE_NAME queue and $CP_CAP_SGE_HOSTLIST_NAME hostlist"
        fi
    )
done

unset _CP_CAP_SGE_DEFAULT_QUEUE_NAME
unset _CP_CAP_SGE_DEFAULT_HOSTLIST_NAME

if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
    /etc/init.d/gridengine-exec restart
elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then
    $SGE_ROOT/$SGE_CELL/common/sgeexecd restart
fi
check_last_exit_code $? "Execution host was restarted" "Fail to restart execution host"

echo "export SGE_ROOT=$SGE_ROOT" >> /etc/cp_env.sh
echo "export SGE_CELL=$SGE_CELL" >> /etc/cp_env.sh
echo "export SGE_CLUSTER_NAME=$SGE_CLUSTER_NAME" >> /etc/cp_env.sh

# Setup any additional SGE consumable resources if available
sge_setup_resources "$HOSTNAME" "$SGE_WORKER_SETUP_TASK" "$_WORKER_CORES"

pipe_log_success "SGE worker node was successfully configured" "$SGE_WORKER_SETUP_TASK"
