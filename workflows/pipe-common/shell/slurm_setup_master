#!/bin/bash

# Copyright 2017-2020 EPAM Systems, Inc. (https://www.epam.com/)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

SLURM_COMMON_CONFIG_DIR="$SHARED_FOLDER/.slurm"
SLURM_MASTER_SETUP_TASK="SLURMMasterSetup"
SLURM_MASTER_SETUP_TASK_WORKERS="SLURMMasterSetupWorkers"
CURRENT_PID=$$

configure_slurm() {
    _SLURM_CONFIG_LOCATION=$( slurm_config_location )

    mkdir -p ${SLURM_COMMON_CONFIG_DIR}

    mkdir -p /var/spool/slurmctld \
             /var/spool/slurmd
    chown slurm: /var/spool/slurmctld \
                 /var/spool/slurmd
    chmod 755 /var/spool/slurmctld \
              /var/spool/slurmd

    touch /var/log/slurmctld.log \
          /var/log/slurm_jobacct.log \
          /var/log/slurm_jobcomp.log
    chown slurm: /var/log/slurmctld.log \
                 /var/log/slurm_jobacct.log \
                 /var/log/slurm_jobcomp.log

    cat > ${SLURM_COMMON_CONFIG_DIR}/cgroup.conf <<EOL
CgroupAutomount=yes
CgroupMountpoint=/cgroup
ConstrainCores=no
ConstrainRAMSpace=no
EOL

    cat > ${SLURM_COMMON_CONFIG_DIR}/slurm.conf <<EOL
ControlMachine=$HOSTNAME
#
#MailProg=/bin/mail
MpiDefault=none
ProctrackType=proctrack/cgroup
ReturnToService=1
SlurmUser=root
SlurmdUser=root
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
SlurmdSpoolDir=/var/spool/slurmd
StateSaveLocation=/var/spool/slurmctld
SwitchType=switch/none
TaskPlugin=task/none

# SCHEDULING
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_CPU

# LOGGING AND ACCOUNTING
ClusterName=cloudpipeline
AccountingStorageType=accounting_storage/none
JobAcctGatherType=jobacct_gather/none
SlurmctldLogFile=/var/log/slurmctld.log
SlurmdLogFile=/var/log/slurmd.log

#
# COMPUTE NODES
EOL

    _WORKER_CORES=$(nproc)
    _NODE_GPUS_COUNT=$(nvidia-smi -L 2>/dev/null | wc -l)
    _NODE_RAM_COUNT=$(grep MemTotal /proc/meminfo | awk '{print int($2 / 1024)}')
    CP_CAP_SGE_MASTER_CORES="${CP_CAP_SGE_MASTER_CORES:-999999999}"
    _WORKER_CORES=$((_WORKER_CORES < CP_CAP_SGE_MASTER_CORES ? _WORKER_CORES : CP_CAP_SGE_MASTER_CORES))

    if (( _NODE_GPUS_COUNT > 0 ))
    then
        echo "GresTypes=gpu" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
        for device in $(ls /dev/ | grep -E "nvidia[0-9]+") ; do
            echo "Name=gpu File=/dev/$device" >> /$_SLURM_CONFIG_LOCATION/gres.conf
        done
    fi

    if [ ! -f "$DEFAULT_HOSTFILE" ]; then
        _NODE_NAMES="$(hostname)"
    else
        IFS=$'\n' read -d '' -r -a _NODE_NAMES < "$DEFAULT_HOSTFILE"
    fi

    for _NODE in ${_NODE_NAMES[*]} ; do
        if (( _NODE_GPUS_COUNT > 0 ))
        then
            echo "NodeName=$_NODE NodeHostname=$_NODE NodeAddr=$(getent hosts $_NODE | awk '{ print $1 }') CPUs=$_WORKER_CORES RealMemory=$_NODE_RAM_COUNT Gres=gpu:$_NODE_GPUS_COUNT State=UNKNOWN" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
        else
            echo "NodeName=$_NODE NodeHostname=$_NODE NodeAddr=$(getent hosts $_NODE | awk '{ print $1 }') CPUs=$_WORKER_CORES RealMemory=$_NODE_RAM_COUNT State=UNKNOWN" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
        fi
    done
    echo "PartitionName=main.q Nodes=ALL Default=YES MaxTime=INFINITE State=UP" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf

    if [ ! -z $CP_SLURM_LICENSES ]; then
        echo "Licenses=$CP_SLURM_LICENSES" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
    fi

    if [ ! -z "${CP_CAP_AUTOSCALE}" ]; then
       echo "" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
       echo "#" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
       echo "#DYNAMIC CLUSTER" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
       echo "MaxNodeCount=$(( ${CP_CAP_AUTOSCALE_WORKERS:-0} + ${node_count:-0} + 1 ))" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
       echo "TreeWidth=65533" >> ${SLURM_COMMON_CONFIG_DIR}/slurm.conf
    fi

    dd if=/dev/urandom bs=1 count=1024 > ${SLURM_COMMON_CONFIG_DIR}/munge.key
    cp ${SLURM_COMMON_CONFIG_DIR}/munge.key /etc/munge/
    chown munge: /etc/munge/munge.key
    chmod 400 /etc/munge/munge.key
    su -c /usr/sbin/munged -s /bin/bash munge

    ln -s ${SLURM_COMMON_CONFIG_DIR}/slurm.conf "$_SLURM_CONFIG_LOCATION"
    ln -s  ${SLURM_COMMON_CONFIG_DIR}/cgroup.conf "$_SLURM_CONFIG_LOCATION"
}

check_last_exit_code() {
   exit_code=$1
   msg_if_success=$2
   msg_if_fail=$3
   if [[ "$exit_code" -ne 0 ]]; then
        pipe_log_fail "$msg_if_fail" "${SLURM_MASTER_SETUP_TASK}"
        kill -s "$CURRENT_PID"
        exit 1
    else
        pipe_log_info "$msg_if_success" "${SLURM_MASTER_SETUP_TASK}"
    fi
}

slurm_config_location() {
   _SLURM_CONFIG_DIR=$(ls /etc/ | grep slurm | head -n 1)
   if [ "$_SLURM_CONFIG_DIR" != "" ]; then
      echo "/etc/$_SLURM_CONFIG_DIR"
   else
      pipe_log_fail "Failed to find SLURM config dir" "${SLURM_MASTER_SETUP_TASK}"
      kill -s "$CURRENT_PID"
      exit 1
   fi
}

install_slurm() {
    create_slurm_user

    if [ "$CP_OS_FAMILY" == "debian" ]; then
        if [ "$CP_OS" == "ubuntu" ] && [ "$CP_VER" == "16.04" ]; then
            pipe_log_fail "SLURM support for Ubuntu 16.04 has been dropped. Please use Ubuntu 18.04 instead." "$SLURM_MASTER_SETUP_TASK"
            return 1
        fi
        install_slurm_debian
    elif [ "$CP_OS_FAMILY" == "rhel" ]; then
        install_slurm_rhel
    else
        return 1
    fi
}

create_slurm_user() {
    export SLURMUSER=992
    groupadd -g $SLURMUSER slurm
    useradd  -m -c "SLURM workload manager" -d /var/lib/slurm -u $SLURMUSER -g slurm  -s /bin/bash slurm
}

install_slurm_debian() {
    apt-get update -y
    apt-get install -y munge

    mkdir -p /var/run/munge \
             /run/munge
    chown munge: /var/run/munge \
                 /run/munge
    chmod +t /run/munge

    wget -q "$CP_SLURM_PACKAGE_DEB_URL" -O /tmp/slurm.deb
    if ! apt-get install -y -f /tmp/slurm.deb; then
        return 1
    fi
    rm -f /tmp/slurm.deb

    mkdir -p /etc/slurm \
             /etc/slurm/prolog.d \
             /etc/slurm/epilog.d
    chown slurm: /etc/slurm \
                 /etc/slurm/prolog.d \
                 /etc/slurm/epilog.d

    ln -s /usr/local/slurm/bin/* /usr/bin/
    ln -s /usr/local/slurm/sbin/* /usr/sbin/

    return 0
}

install_slurm_rhel() {
    yum install epel-release -y
    yum install gcc gcc-c++ mariadb-server mariadb-devel  munge munge-libs munge-devel openssl openssl-devel \
                pam-devel numactl hwloc hwloc-devel lua lua-devel readline-devel rrdtool-devel ncurses-devel  \
                man2html libibmad libibumad rpm-build perl-devel perl-CPAN -y

    _TMP_PACKAGE_DIR=/tmp/localinstall && mkdir -p $_TMP_PACKAGE_DIR
    mkdir -p /common/slurm-pkgs
    wget -q "$CP_SLURM_PACKAGE_RPM_URL" --directory-prefix=$_TMP_PACKAGE_DIR
    if [[ $? -ne 0 ]]; then
        rm -rf /root/rpmbuild/RPMS/x86_64/*
        wget -q $CP_SLURM_SOURCE_URL --directory-prefix=$_TMP_PACKAGE_DIR
        rpmbuild -ta $_TMP_PACKAGE_DIR/slurm*.tar.bz2
        cp /root/rpmbuild/RPMS/x86_64/* /common/slurm-pkgs/
    else
        tar -xf $_TMP_PACKAGE_DIR/slurm*.tar --directory $_TMP_PACKAGE_DIR
        mv $_TMP_PACKAGE_DIR/slurm*/* /common/slurm-pkgs/
    fi

    yum --nogpgcheck localinstall /common/slurm-pkgs/* -y
}

pipe_log_info "Installing SLURM master" "$SLURM_MASTER_SETUP_TASK"

export CP_SLURM_SOURCE_URL="${CP_SLURM_SOURCE_URL:-"${GLOBAL_DISTRIBUTION_URL}tools/slurm/slurm-22.05.5.tar.bz2"}"
export CP_SLURM_PACKAGE_DEB_URL="${CP_SLURM_PACKAGE_DEB_URL:-"${GLOBAL_DISTRIBUTION_URL}tools/slurm/deb/slurm_22.05.5_amd64.deb"}"
export CP_SLURM_PACKAGE_RPM_URL="${CP_SLURM_PACKAGE_RPM_URL:-"${GLOBAL_DISTRIBUTION_URL}tools/slurm/rpm/slurm-22.05.5-1.el7.x86_64.tar"}"

if check_cp_cap CP_CAP_SLURM_PREINSTALLED; then
    pipe_log_info "Skipping SLURM packages installation because packages are preinstalled" "$SLURM_MASTER_SETUP_TASK"
elif check_cp_cap RESUMED_RUN; then
    pipe_log_info "Skipping SLURM packages installation because run is resumed" "$SLURM_MASTER_SETUP_TASK"
else
    pipe_log_info "Installing SLURM packages" "$SLURM_MASTER_SETUP_TASK"
    install_slurm
    check_last_exit_code $? "SLURM packages have been installed" "Can't install SLURM packages"
fi

if check_cp_cap RESUMED_RUN; then
    pipe_log_info "Skipping SLURM cluster configuration because run is resumed" "$SLURM_MASTER_SETUP_TASK"
else
    pipe_log_info "Configuring SLURM cluster" "$SLURM_MASTER_SETUP_TASK"
    configure_slurm
    pipe_log_info "SLURM cluster has been configured" "$SLURM_MASTER_SETUP_TASK"
fi

slurmctld && slurmd
check_last_exit_code $? "SLURM daemons have started" "Fail to start SLURM daemons."

pipe_log_success "SLURM master node has been successfully configured" "$SLURM_MASTER_SETUP_TASK"

# Wait for worker nodes to initiate and connect to the master
if [ -z "$node_count" ] || (( "$node_count" == 0 )); then
    pipe_log_success "Worker nodes count is not defined. Won't wait for execution hosts" "$SLURM_MASTER_SETUP_TASK_WORKERS"
else
    _MASTER_EXEC_WAIT_ATTEMPTS=${_MASTER_EXEC_WAIT_ATTEMPTS:-60}
    _MASTER_EXEC_WAIT_SEC=${_MASTER_EXEC_WAIT_SEC:-10}
    _CURRENT_EXEC_HOSTS_COUNT=$(( $(sinfo -N | grep 'idle' | wc -l) - 1))
    while [ "$node_count" -gt "$_CURRENT_EXEC_HOSTS_COUNT" ]; do
        pipe_log_info "Waiting for execution hosts to connect. $_CURRENT_EXEC_HOSTS_COUNT out of $node_count are ready" "$SLURM_MASTER_SETUP_TASK_WORKERS"
        sleep $_MASTER_EXEC_WAIT_SEC
        _CURRENT_EXEC_HOSTS_COUNT=$(( $(sinfo -N | grep 'idle' | wc -l) - 1))
        _MASTER_EXEC_WAIT_ATTEMPTS=$(( _MASTER_EXEC_WAIT_ATTEMPTS-1 ))

        if (( $_MASTER_EXEC_WAIT_ATTEMPTS <= 0 )); then
            break
        fi
    done
    if [ "$node_count" -gt "$_CURRENT_EXEC_HOSTS_COUNT" ]; then
        pipe_log_success "NOT all execution hosts are connected. But we are giving up waiting as threshold has been reached" "$SLURM_MASTER_SETUP_TASK_WORKERS"
    else
        pipe_log_success "All SLURM hosts are connected" "$SLURM_MASTER_SETUP_TASK_WORKERS"
    fi
fi

(
    export CP_CAP_AUTOSCALE_TASK="SLURMAutoscaling"
    export CP_CAP_SGE_QUEUE_DEFAULT="true"
    export CP_CAP_SGE_QUEUE_STATIC="true"
    nohup "$CP_PYTHON2_PATH" "$COMMON_REPO_DIR/scripts/autoscale_grid_engine.py" >"$LOG_DIR/.nohup.autoscaler.slurm.main.q.log" 2>&1 &
)
