#!/bin/bash

# Copyright 2017-2019 EPAM Systems, Inc. (https://www.epam.com/)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# 1.15.4
#############################
# Kube RPMs download command
#############################
# cat <<EOF >/etc/yum.repos.d/kubernetes.repo
# [kubernetes]
# name=Kubernetes
# baseurl=http://yum.kubernetes.io/repos/kubernetes-el7-x86_64
# enabled=1
# gpgcheck=1
# repo_gpgcheck=1
# gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
#        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
# EOF
# yum -q makecache -y --enablerepo kubernetes --nogpg
# yum install --downloadonly \
#             --downloaddir=/root/kube_dist/other \
#             gettext \
#             kubeadm-1.15.4-0.x86_64 \
#             kubectl-1.15.4-0.x86_64 \
#             kubelet-1.15.4-0.x86_64 \
#             cpp-4.8.5-39.el7.x86_64 \
#             gcc-4.8.5-39.el7.x86_64 \
#             libgcc-4.8.5-39.el7.x86_64 \
#             glibc-2.17-307.el7.1.x86_64 \
#             glibc-common-2.17-307.el7.1.x86_64 \
#             libgcc-4.8.5-39.el7.x86_64

##########################################
# Kube system pods images download command
##########################################
# docker pull calico/node:v3.14.1 && \
# docker save calico/node:v3.14.1 -o calico-node-v3.14.1.tar && \
# docker pull calico/pod2daemon-flexvol:v3.14.1 && \
# docker save calico/pod2daemon-flexvol:v3.14.1 -o calico-pod2daemon-flexvol-v3.14.1.tar && \
# docker pull calico/cni:v3.14.1 && \
# docker save calico/cni:v3.14.1 -o calico-cni-v3.14.1.tar && \
# docker pull calico/kube-controllers:v3.14.1 && \
# docker save calico/kube-controllers:v3.14.1 -o calico-kube-controllers-v3.14.1.tar && \
# docker pull k8s.gcr.io/kube-proxy:v1.15.4 && \
# docker save k8s.gcr.io/kube-proxy:v1.15.4 -o k8s.gcr.io-kube-proxy-v1.15.4.tar && \
# docker pull k8s.gcr.io/kube-apiserver:v1.15.4 && \
# docker save k8s.gcr.io/kube-apiserver:v1.15.4 -o k8s.gcr.io-kube-apiserver-v1.15.4.tar && \
# docker pull k8s.gcr.io/kube-controller-manager:v1.15.4 && \
# docker save k8s.gcr.io/kube-controller-manager:v1.15.4 -o k8s.gcr.io-kube-controller-manager-v1.15.4.tar && \
# docker pull k8s.gcr.io/kube-scheduler:v1.15.4 && \
# docker save k8s.gcr.io/kube-scheduler:v1.15.4 -o k8s.gcr.io-kube-scheduler-v1.15.4.tar && \
# docker pull quay.io/coreos/flannel:v0.11.0 && \
# docker save quay.io/coreos/flannel:v0.11.0 -o quay.io-coreos-flannel-v0.11.0.tar && \
# docker pull k8s.gcr.io/etcd:3.3.10 && \
# docker save k8s.gcr.io/etcd:3.3.10 -o k8s.gcr.io-etcd-3.3.10.tar && \
# docker pull k8s.gcr.io/k8s-dns-sidecar:1.14.13 && \
# docker save k8s.gcr.io/k8s-dns-sidecar:1.14.13 -o k8s.gcr.io-k8s-dns-sidecar-1.14.13.tar && \
# docker pull k8s.gcr.io/k8s-dns-kube-dns:1.14.13 && \
# docker save k8s.gcr.io/k8s-dns-kube-dns:1.14.13 -o k8s.gcr.io-k8s-dns-kube-dns-1.14.13.tar && \
# docker pull k8s.gcr.io/k8s-dns-dnsmasq-nanny:1.14.13 && \
# docker save k8s.gcr.io/k8s-dns-dnsmasq-nanny:1.14.13 -o k8s.gcr.io-k8s-dns-dnsmasq-nanny-1.14.13.tar && \
# docker pull k8s.gcr.io/heapster-amd64:v1.5.4 && \
# docker save k8s.gcr.io/heapster-amd64:v1.5.4 -o k8s.gcr.io-heapster-amd64-v1.5.4.tar && \
# docker pull k8s.gcr.io/pause:3.1 && \
# docker save k8s.gcr.io/pause:3.1 -o k8s.gcr.io-pause-3.1.tar && \
# docker pull k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.1 && \
# docker save k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.1 -o k8s.gcr.io-cluster-proportional-autoscaler-amd64-1.1.1.tar

# 1.28.2
#############################
# Kube RPMs download command
#############################
# yum install epel-release -y
# cat <<EOF >/etc/yum.repos.d/kubernetes.repo
# [kubernetes]
# name=Kubernetes
# baseurl=http://yum.kubernetes.io/repos/kubernetes-el7-x86_64
# enabled=1
# gpgcheck=1
# repo_gpgcheck=1
# gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
#        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
# EOF
# yum -q makecache -y --enablerepo kubernetes --nogpg && \
# mkdir kube && \
# cd kube && \
# yum install --downloadonly \
#             --downloaddir=/root/kube_dist/other \
#             kubeadm-1.28.2-0.x86_64 \
#             kubectl-1.28.2-0.x86_64 \
#             kubelet-1.28.2-0.x86_64 \
#             cpp \
#             gcc \
#             libgcc \
#             glibc \
#             glibc-common \
#             gettext \
#             gettext-libs \
#             iproute \
#             iptables \
#             kernel-headers \
#             libcroco \
#             libmnl \
#             libmpc \
#             libnetfilter_conntrack \
#             libnfnetlink \
#             libunistring \
#             mpfr \
#             tcp_wrappers-libs && \
# cd .. && \
# tar -zcvf kube-1.28.2.tgz kube && \
# aws s3 cp kube-1.28.2.tgz s3://cloud-pipeline-oss-builds/tools/kube/1.28.2/rpm/kube-1.28.2.tgz

##########################################
# Kube system pods images download command
##########################################
# mkdir kube-dockers && \
# cd kube-dockers && \
# docker pull registry.k8s.io/kube-proxy:v1.28.2 && \
# docker save registry.k8s.io/kube-proxy:v1.28.2 -o registry.k8s.io-kube-proxy-v1.28.2.tar && \
# docker pull registry.k8s.io/kube-apiserver:v1.28.2 && \
# docker save registry.k8s.io/kube-apiserver:v1.28.2 -o registry.k8s.io-kube-apiserver-v1.28.2.tar && \
# docker pull registry.k8s.io/kube-controller-manager:v1.28.2 && \
# docker save registry.k8s.io/kube-controller-manager:v1.28.2 -o registry.k8s.io-kube-controller-manager-v1.28.2.tar && \
# docker pull registry.k8s.io/kube-scheduler:v1.28.2 && \
# docker save registry.k8s.io/kube-scheduler:v1.28.2 -o registry.k8s.io-kube-scheduler-v1.28.2.tar && \
# docker pull registry.k8s.io/etcd:3.5.9-0 && \
# docker save registry.k8s.io/etcd:3.5.9-0 -o registry.k8s.io-etcd-3.5.9-0.tar && \
# docker pull registry.k8s.io/coredns/coredns:v1.10.1 && \
# docker save registry.k8s.io/coredns/coredns:v1.10.1 -o registry.k8s.io-coredns-coredns-1.10.1.tar && \
# docker pull registry.k8s.io/pause:3.9 && \
# docker save registry.k8s.io/pause:3.9 -o registry.k8s.io-pause-3.9.tar && \
# docker pull registry.k8s.io/pause:3.8 && \
# docker save registry.k8s.io/pause:3.8 -o registry.k8s.io-pause-3.8.tar && \
# docker pull registry.k8s.io/pause:3.6 && \
# docker save registry.k8s.io/pause:3.6 -o registry.k8s.io-pause-3.6.tar && \
# docker pull docker.io/flannel/flannel-cni-plugin:v1.2.0 && \
# docker save docker.io/flannel/flannel-cni-plugin:v1.2.0 -o docker.io-flannel-flannel-cni-plugin-v1.2.0.tar && \
# docker pull docker.io/flannel/flannel:v0.23.0 && \
# docker save docker.io/flannel/flannel:v0.23.0 -o docker.io-flannel-flannel-v0.23.0.tar && \
# cd .. && \
# tar -zcvf kube-dockers-1.28.2.tgz kube-dockers && \
# aws s3 cp kube-dockers-1.28.2.tgz s3://cloud-pipeline-oss-builds/tools/kube/1.28.2/docker/kube-dockers-1.28.2.tgz


############################
# Input parameters
############################
_kube_common_setup_task_name="$1"
_kube_install_log="$2"
_kube_version="$3"

if [ -z "$_kube_version" ]; then
    pipe_log_fail "[ERROR] kube_setup_common: Kubernetes version is not set" $_kube_common_setup_task_name
    exit 1
fi

############################
# Common functions
############################
function download_distr() {
    local _distr_url="$1"
    local _distr_dir="$2"
    local _distr_file=$_distr_dir/${RANDOM}.tgz
    wget --timeout=10 \
        --waitretry=1 \
        --tries=10 \
        -q \
        "$_distr_url" \
        -O $_distr_file &> $_kube_install_log
    if [ $? -ne 0 ]; then
        pipe_log_fail "[ERROR] Cannot download distribution tarball from $_distr_dir" "$_kube_common_setup_task_name"
        return 1
    fi
    tar -zxf $_distr_file -C $_distr_dir &> $_kube_install_log
    if [ $? -ne 0 ]; then
        pipe_log_fail "[ERROR] Cannot unpack a tarball at $_distr_file" "$_kube_common_setup_task_name"
        return 1
    fi
}

# FIXME: add DEB support as well
_pkg_mngr=$(which_pkg_manager)
if [ "$_pkg_mngr" == "yum" ]; then
    _pkg_type="rpm"
else
    pipe_log_fail "[ERROR] Only RPM-based Linux distibutions are supported for the kubernetes installation" "$_kube_common_setup_task_name"
    exit 1
fi
export CP_CAP_KUBE_DISTR_PREFIX="${CP_CAP_KUBE_DISTR_PREFIX:-"${GLOBAL_DISTRIBUTION_URL}tools/kube"}"
export CP_CAP_KUBE_PACKAGES_DISTR_URL="${CP_CAP_KUBE_PACKAGES_DISTR_URL:-$CP_CAP_KUBE_DISTR_PREFIX/${_kube_version}/$_pkg_type/kube-${_kube_version}.tgz}"
export CP_CAP_KUBE_SYSTEM_PODS_DISTR="${CP_CAP_KUBE_SYSTEM_PODS_DISTR:-$CP_CAP_KUBE_DISTR_PREFIX/${_kube_version}/docker/kube-dockers-${_kube_version}.tgz}"

_node_gpus_count=$(nvidia-smi -L 2>/dev/null | wc -l)
_node_gpus_count="${_node_gpus_count:-0}"

pipe_log_info "- Package manager: $_pkg_type\n \
- Kube version: $_kube_version\n \
- Kube packages URL: $CP_CAP_KUBE_PACKAGES_DISTR_URL\n \
- Kube dockers URL: $CP_CAP_KUBE_SYSTEM_PODS_DISTR\n \
- GPUs count: $_node_gpus_count" "$_kube_common_setup_task_name"

if (( _node_gpus_count > 0 )); then
    pipe_log_info "Installing nvidia-container-toolkit" "$_kube_common_setup_task_name"
    curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo > /etc/yum.repos.d/nvidia-container-toolkit.repo
    # Use absolute path to yum to overcome any wrappers/restrictors
    /usr/bin/yum install -y nvidia-container-toolkit
    rm -f /etc/yum.repos.d/nvidia-container-toolkit.repo
fi

CP_CAP_DIND_CONTAINERD_LOG="${CP_CAP_DIND_CONTAINERD_LOG:-/var/log/containerd.log}"
CP_CAP_DIND_CONTAINERD_BIN="${CP_CAP_DIND_CONTAINERD_BIN:-/usr/local/bin/containerd}"
if [ -f "$CP_CAP_DIND_CONTAINERD_BIN" ]; then
    pipe_log_info "Starting containerd" "$_kube_common_setup_task_name"
    cat > /etc/crictl.yaml <<'EOF'
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
debug: true
EOF
    _containerd_config_file="/etc/containerd/config.toml"
    mkdir -p $(dirname "$_containerd_config_file")
    "$CP_CAP_DIND_CONTAINERD_BIN" config default > "$_containerd_config_file"
    sed -i 's/SystemdCgroup = true/SystemdCgroup = false/' "$_containerd_config_file"

    if (( _node_gpus_count > 0 )); then
        sed -i 's/default_runtime_name = "runc"/default_runtime_name = "nvidia"/' "$_containerd_config_file"
        sed -i '/\[plugins."io.containerd.grpc.v1.cri".containerd.runtimes\]/a\
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]\
          privileged_without_host_devices = false\
          runtime_engine = ""\
          runtime_root = ""\
          runtime_type = "io.containerd.runc.v2"\
          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]\
            BinaryName = "/usr/bin/nvidia-container-runtime"' "$_containerd_config_file"
    fi

    # Configure CRI to work with the private registry
    _dind_registry_certs_dir="/etc/docker/certs.d"
    _cri_registry_certs_dir="/etc/containerd/certs.d"
    if [ -d "$_dind_registry_certs_dir" ]; then
        mkdir -p "$_cri_registry_certs_dir"
        \cp -r $_dind_registry_certs_dir/* $_cri_registry_certs_dir/
        sed -i "s|config_path = \"\"|config_path = \"$_cri_registry_certs_dir\"|" "$_containerd_config_file"

        _cri_registry_list=$(find $_cri_registry_certs_dir -type d)
        for _cri_registry in $_cri_registry_list; do
            [ "$_cri_registry" == "$_cri_registry_certs_dir" ] && continue
            _cri_registry_name=$(basename $_cri_registry)
            sed -i "/\[plugins.\"io.containerd.grpc.v1.cri\".registry.configs\]/a\
\        [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"$_cri_registry_name\".auth]\n\
          username = \"$OWNER\"\n\
          password = \"$API_TOKEN\"\n" "$_containerd_config_file"
        done
        pipe_log_info "Containerd private registry access is configured (using docker config from $_dind_registry_certs_dir)" "$_kube_common_setup_task_name"
    else
        pipe_log_warn "Cannot setup private registry access for containerd as the docker config is missing at $_dind_registry_certs_dir" "$_kube_common_setup_task_name"
    fi

    nohup "$CP_CAP_DIND_CONTAINERD_BIN" &> "$CP_CAP_DIND_CONTAINERD_LOG" &
else
    pipe_log_warn "containerd binary not found at $CP_CAP_DIND_CONTAINERD_BIN" "$_kube_common_setup_task_name"
fi

######################################
# Install kubelet and management tools
######################################
pipe_log_info "Getting kubernetes packages" "$_kube_common_setup_task_name"

_packages_distr_dir=$(mktemp -d)
download_distr "$CP_CAP_KUBE_PACKAGES_DISTR_URL" "$_packages_distr_dir" || exit 1

yum localinstall -y $_packages_distr_dir/kube/*.rpm &> $_kube_install_log
if [ $? -ne 0 ]; then
    pipe_log_fail "[ERROR] Cannot install kubernetes packages from $_packages_distr_dir" "$_kube_common_setup_task_name"
    exit 1
fi
rm -rf $_packages_distr_dir

pipe_log_info "All kubernetes packages are installed" "$_kube_common_setup_task_name"

############################################################
# Install the kubernetes dockers (API/Scheduler/Network/etc)
############################################################
pipe_log_info "Getting system docker images" "$_kube_common_setup_task_name"

_docker_distr_dir=$(mktemp -d)
download_distr "$CP_CAP_KUBE_SYSTEM_PODS_DISTR" "$_docker_distr_dir" || exit 1
for _docker_tar in $_docker_distr_dir/kube-dockers/*.tar; do
    if util_version_compare "$_kube_version" "1.24.0" ">"; then
        ctr -n=k8s.io images import "$_docker_tar"
    else
        docker load -i $_docker_tar &> $_kube_install_log
    fi
    if [ $? -ne 0 ]; then
        pipe_log_fail "[ERROR] Cannot load the docker image from the tarball at $_docker_tar" "$_kube_common_setup_task_name"
        exit 1
    fi
    pipe_log_info "$_docker_tar has been loaded" "$_kube_common_setup_task_name"
done
rm -rf $_docker_distr_dir

pipe_log_info "All system docker images are loaded" "$_kube_common_setup_task_name"
