#!/bin/bash

# Copyright 2017-2019 EPAM Systems, Inc. (https://www.epam.com/)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

SGE_MASTER_SETUP_TASK="SGEMasterSetup"
SGE_MASTER_SETUP_TASK_WORKERS="SGEMasterSetupWorkers"
CURRENT_PID=$$

add_worker() {
    QUEUE=$1
	SLOTS=$2

    # add to the execution host list
    TMPFILE=/tmp/sge.hostname-$HOSTNAME
    echo -e "hostname $HOSTNAME\nload_scaling NONE\ncomplex_values NONE\nuser_lists NONE\nxuser_lists NONE\nprojects NONE\nxprojects NONE\nusage_scaling NONE\nreport_variables NONE" > $TMPFILE
    qconf -Ae $TMPFILE
    rm -f $TMPFILE

    # add to the all hosts list
    qconf -aattr hostgroup hostlist $HOSTNAME @allhosts

    # enable the host for the queue, in case it was disabled and not removed
    qmod -e $QUEUE@$HOSTNAME

    qconf -as "$HOSTNAME"
    qconf -ah "$HOSTNAME"

	if [ "$SLOTS" ]; then
        qconf -aattr queue slots "[$HOSTNAME=$SLOTS]" $QUEUE
	fi
}

create_hostlist() {
        echo -e "group_name @allhosts\nhostlist NONE" > ./grid
        qconf -Ahgrp ./grid
        rm -f ./grid
}

configure_global() {
    _MAX_PROCS_LIMIT="${MAX_PROCS_LIMIT:-65536}"
    _MAX_NOPEN_LIMIT="${MAX_NOPEN_LIMIT:-65536}"
    _SHELL_START_MODE="${CP_CAP_SGE_SHELL_START_MODE:-unix_behavior}"
    _SGE_REPORTING_PARAMS="${CP_CAP_SGE_REPORTING_PARAMS:-"accounting=true reporting=true flush_time=00:01:00 joblog=true sharelog=00:00:00"}"

    qconf -sconf global > ./global
    # Some of the long values (reporting_params, execd_params, etc.) are split into several line with a backslash. E.g.:
    # reporting_params accounting=true reporting=false \
    #                  flush_time=00:00:15 joblog=false sharelog=00:00:00
    # To replace the value - we need to merge all these line into one
    # The next "magic" line reads a file line-by-line and removes all "backslash + newline" (\\n)
    sed -i ':a;N;$!ba;s/\\\n//g' ./global
    sed -i '/min_uid/c\min_uid 0' ./global
    sed -i '/min_gid/c\min_gid 0' ./global
    sed -i "/execd_params/c\execd_params S_DESCRIPTORS=${_MAX_PROCS_LIMIT},H_DESCRIPTORS=${_MAX_PROCS_LIMIT},S_MAXPROC=${_MAX_NOPEN_LIMIT},H_MAXPROC=${_MAX_NOPEN_LIMIT}" ./global
    sed -i "/shell_start_mode/c\shell_start_mode $_SHELL_START_MODE" ./global
    sed -i "/reporting_params/c\reporting_params $_SGE_REPORTING_PARAMS" ./global

    qconf -Mconf ./global
    rm -f ./global
}

configure_scheduler() {
    cat > ./grid <<EOL
    algorithm                         default
    schedule_interval                 0:0:1
    maxujobs                          0
    queue_sort_method                 load
    job_load_adjustments              np_load_avg=0.50
    load_adjustment_decay_time        0:7:30
    load_formula                      np_load_avg
    schedd_job_info                   true
    flush_submit_sec                  0
    flush_finish_sec                  0
    params                            none
    reprioritize_interval             0:0:0
    halftime                          168
    usage_weight_list                 cpu=1.000000,mem=0.000000,io=0.000000
    compensation_factor               5.000000
    weight_user                       0.250000
    weight_project                    0.250000
    weight_department                 0.250000
    weight_job                        0.250000
    weight_tickets_functional         0
    weight_tickets_share              0
    share_override_tickets            TRUE
    share_functional_shares           TRUE
    max_functional_jobs_to_schedule   200
    report_pjob_tickets               TRUE
    max_pending_tasks_per_job         50
    halflife_decay_list               none
    policy_hierarchy                  OFS
    weight_ticket                     0.500000
    weight_waiting_time               0.278000
    weight_deadline                   3600000.000000
    weight_urgency                    0.500000
    weight_priority                   0.000000
    max_reservation                   0
    default_duration                  INFINITY
EOL
    qconf -Msconf ./grid
    rm -f ./grid
}

add_queue() {
        QUEUE=$1

        # Delete any existing-default queues, before adding a new one
        _CURRENT_QUEUES=$(qconf -sql)
        for _Q in $_CURRENT_QUEUES; do 
            qconf -dq "$_Q"
        done

        cat > ./grid <<EOL
        qname                 $QUEUE
        hostlist              @allhosts
        seq_no                0
        load_thresholds       NONE
        suspend_thresholds    NONE
        nsuspend              1
        suspend_interval      00:00:01
        priority              0
        min_cpu_interval      00:00:01
        processors            UNDEFINED
        qtype                 BATCH INTERACTIVE
        ckpt_list             NONE
        pe_list               make
        rerun                 FALSE
        slots                 2
        tmpdir                /tmp
        shell                 /bin/bash
        prolog                NONE
        epilog                NONE
        shell_start_mode      unix_behavior
        starter_method        NONE
        suspend_method        NONE
        resume_method         NONE
        terminate_method      NONE
        notify                00:00:01
        owner_list            NONE
        user_lists            NONE
        xuser_lists           NONE
        subordinate_list      NONE
        complex_values        NONE
        projects              NONE
        xprojects             NONE
        calendar              NONE
        initial_state         default
        s_rt                  INFINITY
        h_rt                  INFINITY
        s_cpu                 INFINITY
        h_cpu                 INFINITY
        s_fsize               INFINITY
        h_fsize               INFINITY
        s_data                INFINITY
        h_data                INFINITY
        s_stack               INFINITY
        h_stack               INFINITY
        s_core                INFINITY
        h_core                INFINITY
        s_rss                 INFINITY
        h_rss                 INFINITY
        s_vmem                INFINITY
        h_vmem                INFINITY
EOL
        qconf -Aq ./grid
        rm -f ./grid
}

delete_pe() {
    local pe_all="$1"

    local current_pe_list="$pe_all"
    if [ "$current_pe_list" == "all" ]; then
        current_pe_list=$(qconf -spl)
    fi

    for _pe_name in $current_pe_list; do 
        qconf -dp "$_pe_name"
    done
}

create_pe_from_file() {
    local pe_spec_file="$1"
    local pe_queue_name="${2:-$CP_CAP_SGE_QUEUE_NAME}"
    if [ -z "$pe_spec_file" ]; then
        echo "PE spec file is not provided"
        return 1
    fi
    if [ ! -f "$pe_spec_file" ]; then
        echo "PE spec file is not found at ${pe_spec_file}"
        return 1
    fi

    local pe_name=$(echo $(cat "$pe_spec_file" | grep pe_name) | cut -f2 -d' ')
    if [ -z "$pe_name" ]; then
        echo "Cannot get PE name from $pe_spec_file"
        return 1
    fi

    qconf -Ap "$pe_spec_file"
    qconf -mattr queue pe_list "$pe_name" "$pe_queue_name"
}

configure_pe() {
    local pe_name="${1:-local}"
    local pe_alloc_rule="${2:-\$pe_slots}"
    local pe_job_is_first_task="${3:-TRUE}"
    local pe_slots="${4}"

    if [ -z "$pe_slots" ]; then
        pe_slots=${CLOUD_PIPELINE_CLUSTER_CORES:-999999}
    fi

    cat > pe.conf <<EOL
        pe_name            $pe_name
        slots              $pe_slots
        user_lists         NONE
        xuser_lists        NONE
        start_proc_args    NONE
        stop_proc_args     NONE
        allocation_rule    $pe_alloc_rule
        control_slaves     TRUE
        job_is_first_task  $pe_job_is_first_task
        urgency_slots      min
        accounting_summary FALSE
        qsort_args         NONE
EOL
    qconf -Ap pe.conf
    qconf -mattr queue pe_list "$pe_name" "$CP_CAP_SGE_QUEUE_NAME"
    rm -f pe.conf
}

run_redhat_installation() {
    _SGE_ROLE=$1

    cat > ./grid.conf <<EOL
    SGE_ROOT="/opt/sge"
    SGE_QMASTER_PORT=6444
    SGE_EXECD_PORT=6445
    SGE_ENABLE_SMF="false"
    SGE_CLUSTER_NAME="${SGE_CLUSTER_NAME}"
    SGE_JMX_SSL="false"
    SGE_JMX_SSL_CLIENT="false"
    CELL_NAME=default
    ADMIN_USER=sgeadmin
    QMASTER_SPOOL_DIR="$SGE_ROOT/default/spool/qmaster"
    EXECD_SPOOL_DIR="$SGE_ROOT/default/spool"
    GID_RANGE="20000-30000"
    SPOOLING_METHOD="classic"
    DB_SPOOLING_DIR="spooldb"
    PAR_EXECD_INST_COUNT="20"
    EXECD_SPOOL_DIR_LOCAL="$SGE_ROOT/default/spool/$HOSTNAME"
    SHELL_NAME="ssh"
    DEFAULT_DOMAIN="none"
    ADD_TO_RC="false"
    SET_FILE_PERMS="false"
    RESCHEDULE_JOBS="wait"
    SCHEDD_CONF="1"
    SHADOW_HOST=""
    ADMIN_MAIL="none"
    HOSTNAME_RESOLVING="false"
    EXEC_HOST_LIST="$HOSTNAME"
    SUBMIT_HOST_LIST="$HOSTNAME"
EOL

    cd "$SGE_ROOT"
    ./inst_sge -m -auto ./grid.conf
    result=$?
    . "$SGE_ROOT/$SGE_CELL/common/settings.sh"
    ln -s /opt/sge/bin/lx-amd64/* /bin

    check_last_exit_code "$result" "$_SGE_ROLE host was successfully configured" \
                                "Failed to configure $_SGE_ROLE host"

    rm -f ./grid.conf
}

get_linux_dist() {
    result=
    command -v apt-get > /dev/null
    if [ $? -eq 0 ]; then
        result="debian"
    fi

    command -v yum > /dev/null
    if [ $? -eq 0 ]; then
        result="redhat"
    fi

    echo "$result"
}

check_last_exit_code() {
   exit_code=$1
   msg_if_success=$2
   msg_if_fail=$3
   if [[ "$exit_code" -ne 0 ]]; then
        pipe_log_fail "$msg_if_fail" "${SGE_MASTER_SETUP_TASK}"
        kill -s "$CURRENT_PID"
        exit 1
    else
        pipe_log_info "$msg_if_success" "${SGE_MASTER_SETUP_TASK}"
    fi
}

LINUX_DISTRIBUTION=$( get_linux_dist )

#Remove pipe qsub, if exists
$CP_PYTHON2_PATH -m pip uninstall -y -q PipelineQSUB

pipe_log_info "Installing SGE master" "$SGE_MASTER_SETUP_TASK"

# Set SGE env vars, and store in cp_env.sh for further ssh sessions
export SGE_CELL="default"
export SGE_CLUSTER_NAME="CLOUD_PIPELINE"
export CP_CAP_SGE_QUEUE_NAME="${CP_CAP_SGE_QUEUE_NAME:-main.q}"
export CP_CAP_SGE_PE_NAME="${CP_CAP_SGE_PE_NAME:-local}"
export CP_CAP_SGE_PE_SLOTS="${CP_CAP_SGE_PE_SLOTS:-999999}"
export CP_CAP_SGE_PE_MPI_NAME="${CP_CAP_SGE_PE_MPI_NAME:-mpi}"
export CP_CAP_SGE_PE_MPI_SLOTS="${CP_CAP_SGE_PE_MPI_SLOTS:-999999}"
export CP_CAP_SGE_WORKER_FREE_CORES="${CP_CAP_SGE_WORKER_FREE_CORES:-0}"

if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
    export SGE_ROOT="/var/lib/gridengine"
elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then
    export SGE_ROOT="/opt/sge"
fi
export SHARED_FOLDER=${SHARED_FOLDER:-"/common"}
CP_CAP_SCRIPTS_DIR="${CP_CAP_SCRIPTS_DIR:-$SHARED_FOLDER/cap_scripts}"
CP_CAP_SGE_MASTER_ENV_FILE="${CP_CAP_SCRIPTS_DIR}/sge_master_env.sh"
mkdir -p "$CP_CAP_SCRIPTS_DIR"
echo "export SGE_ROOT=$SGE_ROOT" > $CP_CAP_SGE_MASTER_ENV_FILE
echo "export SGE_CELL=$SGE_CELL" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export SGE_CLUSTER_NAME=$SGE_CLUSTER_NAME" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export CP_CAP_SGE_QUEUE_NAME=$CP_CAP_SGE_QUEUE_NAME" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export CP_CAP_SGE_PE_NAME=$CP_CAP_SGE_PE_NAME" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export CP_CAP_SGE_PE_SLOTS=$CP_CAP_SGE_PE_SLOTS" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export CP_CAP_SGE_PE_MPI_NAME=$CP_CAP_SGE_PE_MPI_NAME" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export CP_CAP_SGE_PE_MPI_SLOTS=$CP_CAP_SGE_PE_MPI_SLOTS" >> $CP_CAP_SGE_MASTER_ENV_FILE
echo "export CP_CAP_SGE_WORKER_FREE_CORES=$CP_CAP_SGE_WORKER_FREE_CORES" >> $CP_CAP_SGE_MASTER_ENV_FILE
cat $CP_CAP_SGE_MASTER_ENV_FILE >> /etc/cp_env.sh


# Verify whether it is a resumed run - if so, do not reinstall sge, instead - just rerun master and exec daemon
if [ "$RESUMED_RUN" = true ]; then
    pipe_log_info "Run is resumed - SGE master node won't be reconfigured. Starting master and exec daemons" "$SGE_MASTER_SETUP_TASK"
    _SGE_RESUME_RESULT=0
    if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
        /etc/init.d/gridengine-master restart && \
        /etc/init.d/gridengine-exec restart
        _SGE_RESUME_RESULT=$?
    elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then
        $SGE_ROOT/$SGE_CELL/common/sgemaster restart && \
        $SGE_ROOT/$SGE_CELL/common/sgeexecd restart
        _SGE_RESUME_RESULT=$?
    fi
    
    if [ $_SGE_RESUME_RESULT -eq 0 ]; then
        pipe_log_success "SGE daemons started" "$SGE_MASTER_SETUP_TASK"
    else
        pipe_log_fail "SGE daemons start failed. See any errors in the ConsoleOutput" "$SGE_MASTER_SETUP_TASK"
    fi
    exit 0
fi


IFS='@' read -r -a owner_info <<< "$OWNER"
OWNER_NAME="${owner_info[0]}"

if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
    if [ "$CP_CAP_SGE_PREINSTALLED" != "true" ]; then
        rm -rf /var/lib/gridengine/
        apt-get remove gridengine-client gridengine-common gridengine-master gridengine-exec --purge -y

        # Install Grid Engine
        # Configure the master hostname for Grid Engine
        CP_CAP_SGE_VERSION="${CP_CAP_SGE_VERSION:-8.1.9+dfsg-4*}"

        # First install SGE, and fail if error occurs
        DEBIAN_FRONTEND=noninteractive apt-get install -y --allow-unauthenticated -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" gridengine-exec="$CP_CAP_SGE_VERSION" \
            gridengine-client="$CP_CAP_SGE_VERSION" \
            gridengine-common="$CP_CAP_SGE_VERSION" \
            gridengine-master="$CP_CAP_SGE_VERSION" > /dev/null

        check_last_exit_code $? "All SGE packages were installed" "Fail to install SGE master"

        # Next - try to install any non-mandatory packages, and igore them if error occurs
        DEBIAN_FRONTEND=noninteractive apt-get install -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" sudo locales > /dev/null

        if [ $? -ne 0 ]; then
            pipe_log_warn "Additional SGE packages were not installed, error is ignored" "$SGE_MASTER_SETUP_TASK"
        fi
    fi

    ## Configure default locale, see https://github.com/rocker-org/rocker/issues/19
    echo "en_US.UTF-8 UTF-8" >> /etc/locale.gen \
	&& locale-gen en_US.UTF-8 \
	&& /usr/sbin/update-locale LANG=en_US.UTF-8

    export LC_ALL=en_US.UTF-8
    export LANG=en_US.UTF-8

    echo "gridengine-master       shared/gridenginemaster string  $HOSTNAME" |  debconf-set-selections
    echo "gridengine-master       shared/gridenginecell   string  default" |  debconf-set-selections
    echo "gridengine-master       shared/gridengineconfig boolean false" |  debconf-set-selections
    echo "gridengine-common       shared/gridenginemaster string  $HOSTNAME" |  debconf-set-selections
    echo "gridengine-common       shared/gridenginecell   string  default" |  debconf-set-selections
    echo "gridengine-common       shared/gridengineconfig boolean false" |  debconf-set-selections
    echo "gridengine-client       shared/gridenginemaster string  $HOSTNAME" |  debconf-set-selections
    echo "gridengine-client       shared/gridenginecell   string  default" |  debconf-set-selections
    echo "gridengine-client       shared/gridengineconfig boolean false" |  debconf-set-selections
    # Postfix mail server is also installed as a dependency
    echo "postfix postfix/main_mailer_type        select  No configuration" |  debconf-set-selections
    # Set up Grid Engine
    pipe_log_info "Setup Grid Engine, adding sgeadmin" "$SGE_MASTER_SETUP_TASK"

    sudo -u sgeadmin /usr/share/gridengine/scripts/init_cluster "$SGE_ROOT" default /var/spool/gridengine/spooldb sgeadmin
    echo "$HOSTNAME" |  tee "$SGE_ROOT"/"$SGE_CELL"/common/act_qmaster
    /etc/init.d/gridengine-master restart
    check_last_exit_code $? "Master host was successfully configured" "Failed to configure master host"

elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then   
    if [ "$CP_CAP_SGE_PREINSTALLED" != "true" ]; then
        yum remove -y -q gridengine-*
        rm -rf /opt/sge/*
        rm -rf /etc/rc.d/init.d/*.CLOUD_PIPELINE

        yum install -y -q perl perl-Env.noarch perl-Exporter.noarch perl-File-BaseDir.noarch \
                            perl-Getopt-Long.noarch perl-libs perl-POSIX-strptime.x86_64 \
                            perl-XML-Simple.noarch jemalloc munge-libs hwloc lesstif csh \
                            ruby xorg-x11-fonts xterm java xorg-x11-fonts-ISO8859-1-100dpi \
                            xorg-x11-fonts-ISO8859-1-75dpi mailx libdb4 libdb4-utils \
                            compat-db-headers compat-db47 libpipeline man-db

        yum install -y -q gridengine \
                            gridengine-debuginfo \
                            gridengine-devel \
                            gridengine-drmaa4ruby \
                            gridengine-execd \
                            gridengine-guiinst \
                            gridengine-qmaster \
                            gridengine-qmon
    fi

    check_last_exit_code $? "All SGE packages were installed" "Fail to install SGE worker"

    QMASTER_HOST="$HOSTNAME"

    cd "$SGE_ROOT"
    run_redhat_installation "master"
fi

qconf -as "$HOSTNAME"
qconf -ah "$HOSTNAME"

pipe_log_info "Configure hostlist, global, scheduler, queue" "$SGE_MASTER_SETUP_TASK"

create_hostlist
check_last_exit_code $? "Hostlist was configured" "Fail to configure hostlist"

configure_global
check_last_exit_code $? "Global settings were configured" "Failed to configure global settings"

configure_scheduler
check_last_exit_code $? "Scheduler was configured" "Fail to configure scheduler"

add_queue "$CP_CAP_SGE_QUEUE_NAME"
check_last_exit_code $? "Queue was configured" "Fail to configure queue"

#add local worker

# If CP_CAP_SGE_MASTER_CORES is set to "0" - we'll not use master as a worker
if [ "$CP_CAP_SGE_MASTER_CORES" == "0" ]; then
    pipe_log_info "CP_CAP_SGE_MASTER_CORES is set to 0. Master host was NOT added as a worker" "$SGE_MASTER_SETUP_TASK"
else
    # If CP_CAP_SGE_MASTER_CORES is set - then we'll it's value:
    # - if larger that nproc - use nproc
    # - if less - use CP_CAP_SGE_MASTER_CORES, e.g. if we'd like to keep some cores free
    # If CP_CAP_SGE_MASTER_CORES not set - use nproc
    _MASTER_WORKER_CORES=$(nproc)
    CP_CAP_SGE_MASTER_CORES="${CP_CAP_SGE_MASTER_CORES:-999999999}"
    _MASTER_WORKER_CORES=$((_MASTER_WORKER_CORES < CP_CAP_SGE_MASTER_CORES ? _MASTER_WORKER_CORES : CP_CAP_SGE_MASTER_CORES))

    # If a certain number of cores, shall be reserved (outside the SGE): CP_CAP_SGE_WORKER_FREE_CORES can be used
    # Total number of the worker slots is calculated as (_MASTER_WORKER_CORES - CP_CAP_SGE_WORKER_FREE_CORES). If the result <= 0: _MASTER_WORKER_CORES is used 
    _MASTER_WORKER_CORES_BKP=$_MASTER_WORKER_CORES
    CP_CAP_SGE_WORKER_FREE_CORES="${CP_CAP_SGE_WORKER_FREE_CORES:-0}"
    _MASTER_WORKER_CORES=$(($_MASTER_WORKER_CORES - $CP_CAP_SGE_WORKER_FREE_CORES))
    (( $_MASTER_WORKER_CORES <= 0 )) && _MASTER_WORKER_CORES=$_MASTER_WORKER_CORES_BKP

    add_worker "$CP_CAP_SGE_QUEUE_NAME" "$_MASTER_WORKER_CORES"
    check_last_exit_code $? "Master host was added as a worker with $_MASTER_WORKER_CORES slots" "Fail to add master host as a SGE worker"

    if [ "$LINUX_DISTRIBUTION" = "debian" ]; then
        /etc/init.d/gridengine-exec restart
    elif [ "$LINUX_DISTRIBUTION" = "redhat" ]; then
        $SGE_ROOT/$SGE_CELL/common/sgeexecd restart
    fi
fi

pipe_log_info "Add $OWNER_NAME as SGE manager and operator" "$SGE_MASTER_SETUP_TASK"
qconf -am $OWNER_NAME
qconf -ao $OWNER_NAME

# Configure Parallel Environments and attach to the queue ($CP_CAP_SGE_QUEUE_NAME)
# - First delete all default PEs
delete_pe all
# - Add a "threaded/smp" PE, which schedules all threads to a single machine
configure_pe "$CP_CAP_SGE_PE_NAME" \
             "\$pe_slots" \
             "TRUE" \
             "$CP_CAP_SGE_PE_SLOTS"
# - Add an "mpi" PE, which allows to spread processes across nodes
configure_pe "$CP_CAP_SGE_PE_MPI_NAME" \
             "\$fill_up" \
             "FALSE" \
             "$CP_CAP_SGE_PE_MPI_SLOTS"
# - Add any other user-provided PEs
if [ "$CP_CAP_SGE_EXTRA_PE_PATH" ] && [ -d "$CP_CAP_SGE_EXTRA_PE_PATH" ]; then
    pipe_log_info "Extra PEs are provided via ${CP_CAP_SGE_EXTRA_PE_PATH}, setting them up" "$SGE_MASTER_SETUP_TASK"
    for _pe_spec_file in $CP_CAP_SGE_EXTRA_PE_PATH/*.spec; do
        pipe_log_info "-> Configuring PE from $_pe_spec_file" "$SGE_MASTER_SETUP_TASK"
        create_pe_from_file "$_pe_spec_file"
    done
else
    pipe_log_info "No extra PEs are provided, skipping setup" "$SGE_MASTER_SETUP_TASK"
fi

# Setup any additional SGE consumable resources if available
sge_setup_resources "$HOSTNAME" "$SGE_MASTER_SETUP_TASK" "$_MASTER_WORKER_CORES"

pipe_log_success "SGE master node was successfully configured" "$SGE_MASTER_SETUP_TASK"

# Wait for worker nodes to initiate and connect to the master
if [ -z "$node_count" ] || (( "$node_count" == 0 )); then
    pipe_log_success "Worker nodes count is not defined. Won't wait for execution hosts" "$SGE_MASTER_SETUP_TASK_WORKERS"
else
    _MASTER_EXEC_WAIT_ATTEMPTS=${_MASTER_EXEC_WAIT_ATTEMPTS:-60}
    _MASTER_EXEC_WAIT_SEC=${_MASTER_EXEC_WAIT_SEC:-10}
    _CURRENT_EXEC_HOSTS_COUNT=$(( $(qconf -sel | wc -l) - 1))
    while [ "$node_count" -gt "$_CURRENT_EXEC_HOSTS_COUNT" ]; do
        pipe_log_info "Waiting for execution hosts to connect. $_CURRENT_EXEC_HOSTS_COUNT out of $node_count are ready" "$SGE_MASTER_SETUP_TASK_WORKERS"
        sleep $_MASTER_EXEC_WAIT_SEC
        _CURRENT_EXEC_HOSTS_COUNT=$(( $(qconf -sel | wc -l) - 1))
        _MASTER_EXEC_WAIT_ATTEMPTS=$(( _MASTER_EXEC_WAIT_ATTEMPTS-1 ))

        if (( $_MASTER_EXEC_WAIT_ATTEMPTS <= 0 )); then
            pipe_log_success "NOT all execution hosts are connected. But we are giving up waiting as threshold has been reached" "$SGE_MASTER_SETUP_TASK_WORKERS"
            exit 0
        fi
    done
    pipe_log_success "All execution hosts are connected" "$SGE_MASTER_SETUP_TASK_WORKERS"
fi
