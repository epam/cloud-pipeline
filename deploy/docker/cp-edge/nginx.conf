user             root;
worker_processes auto;
error_log        /etc/nginx/logs/error.log;
pid              /usr/local/openresty/nginx/logs/nginx.pid;
include          /usr/share/nginx/modules/*.conf;

events {
    worker_connections 1024;
}

env JWT_PUB_KEY;
env API;
env API_EXTERNAL;
env EDGE_EXTERNAL;
env EDGE_EXTERNAL_SCHEMA;

# - SSL/TLS traffic will go to port 8181 (HTTP Reverse proxy for interactive web and in-browser sessions)
# - While plain HTTP traffic will go to a forward proxy and will be considered as HTTP CONNECT method 
#   (this is typically used for the noMachine sessions, which does not support HTTPS CONNECT)
stream {
    upstream reverse_proxy {
        server 127.0.0.1:8181;
    }

    upstream forward_proxy {
        server 127.0.0.1:8282;
    }

    map $ssl_preread_protocol $proxy_type {
        "" forward_proxy;
        default reverse_proxy;
    }

    server {
        listen 8080;

        proxy_pass $proxy_type;
        ssl_preread on;
    }
}

http {
    # CP_EDGE_WEB_CLIENT_MAX_SIZE is replaced in the `init` script
    client_max_body_size    $CP_EDGE_WEB_CLIENT_MAX_SIZE;
    proxy_http_version      1.1;
    proxy_buffering         off;
    proxy_request_buffering off;
    log_format              main '$remote_addr - $remote_user [$time_local] "$request" '
                            '$status $body_bytes_sent "$http_referer" '
                            '"$http_user_agent" "$http_x_forwarded_for"';

    access_log              /etc/nginx/logs/access.log  main;
    lua_package_path        "/usr/local/openresty/lualib/?.lua;;";

    # Health endpoints
    server {
        listen 8888 default_server;

        # A basic nginx health check, which ensures that nginx is up/running and can server the requests
        location /edge-health {
            access_log off;
            return 200 "healthy\n";
        }

        # Web TTY ping, which ensures that SSH service is there
        location /wetty-health {
            access_log off;
            proxy_pass http://127.0.0.1:32000/;
            proxy_connect_timeout   5s;
            proxy_send_timeout      5s;
            proxy_read_timeout      5s;
        }
    }

    # "Endpoints" routes with custom domains
    # These routes are defined in the separate "server { server_name }" blocks with the server_name
    include /etc/nginx/sites-enabled/custom-domains/*.srv.conf;

    # Main proxy setup
    server {
        listen                      8181 ssl default_server;

        # Server block shared configuration for all the "Endpoints"
        include /etc/nginx/endpoints-config/server.common.conf;

        # "Endpoints" routes WITHOUT custom domains
        # These routes are defined in the "location" blocks
        include /etc/nginx/sites-enabled/*.loc.conf;

        location /ssh {
            default_type        text/html;
            access_by_lua_file  /etc/nginx/validate_cookie_ssh.lua;
            proxy_pass          http://127.0.0.1:32000/ssh;
            proxy_http_version  1.1;
            proxy_set_header    Upgrade $http_upgrade;
            proxy_set_header    Connection "upgrade";
            proxy_read_timeout  43200000;

            proxy_set_header    X-Real-IP $remote_addr;
            proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header    Host $http_host;
            proxy_set_header    X-NginX-Proxy true;
        }

        location /${CP_DAV_URL_PATH} {
            default_type            text/html;
            access_by_lua_file      /etc/nginx/validate_cookie_dav.lua;
            # Internal cluster DNS is used to resolve the .cluster.local correctly
            # As the NGINX resolves the names only at a startup time
            # If the DAV service is recreated - it's IP is changed and EDGE will throw Gateway Timeout
            resolver                ${CP_EDGE_CLUSTER_RESOLVER} valid=${CP_EDGE_CLUSTER_RESOLVER_TIMEOUT_SEC}s ipv6=off;
            # We also need to set the backend (proxied host) as a variable, so nginx will force name resolution each "valid" interval
            # See https://serverfault.com/questions/240476/how-to-force-nginx-to-resolve-dns-of-a-dynamic-hostname-everytime-when-doing-p/593003#593003
            set                     $cp_dav_backend "http://${CP_DAV_INTERNAL_HOST}:${CP_DAV_INTERNAL_PORT}";
            proxy_pass              $cp_dav_backend;
            proxy_set_header        Host $http_host;
            proxy_pass_header       Server;
            proxy_redirect          "http://" "${EDGE_EXTERNAL_SCHEMA}://";
            client_max_body_size    0;

            # Rewrite the "Destination" header (which is used to specify dest for the MOVE operation) to the internal address of the upstream DAV server, e.g.:
            # Client: "Destination: https://1.1.1.1:31081/webdav/folder/file.txt"
            # Nginx rewrites to: "Destination: http://cp-dav.default.cluster.local:8080/webdav/folder/file.txt"
            # Substitution happens in the lua script at /etc/nginx/validate_cookie_dav.lua
            # The script sets dav_dest_path variable
            set $dav_dest_path "";
            proxy_hide_header Destination;
            proxy_set_header  Destination $dav_dest_path;
        }

        location /${CP_DAV_AUTH_URL_PATH}/ {
            default_type        text/html;
            access_by_lua_file  /etc/nginx/create_cookie_dav.lua;
            root                /etc/nginx/dav;
        }
    }

    server {
        listen                         8282;

        # dns resolver used by forward proxying
        resolver                       ${CP_EDGE_CLUSTER_RESOLVER};

        # forward proxy for CONNECT request
        proxy_connect;
        proxy_connect_allow            all;
        proxy_connect_connect_timeout  3600s;
        proxy_connect_read_timeout     3600s;
        proxy_connect_send_timeout     3600s;
    }
}
